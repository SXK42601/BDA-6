{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opuolrlX5Ed4",
        "outputId": "e752d2a2-7c7d-400b-9598-c7979de6395e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/diabetes(1).csv'"
      ],
      "metadata": {
        "id": "JQiq7Kk25ShQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8], test_size=0.1, random_state=30)\n",
        "\n",
        "np.random.seed(155)\n",
        "\n",
        "my_first_nn = Sequential()\n",
        "my_first_nn.add(Dense(16, activation='relu', input_shape=(8,)))\n",
        "my_first_nn.add(Dense(8, activation='relu'))\n",
        "my_first_nn.add(Dense(64, activation='relu'))\n",
        "my_first_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "my_first_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "loss, accuracy = my_first_nn.evaluate(X_test, Y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "vSjjo5bzDcpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfeba2b-c675-410c-983b-489e70570607"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.6483\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.6498\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.6483\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.6339\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.6469\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.6758\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.6599\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.6425\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.6643\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.6585\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.6483\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.6483\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.6527\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.6657\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.6715\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.6715\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.7019\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.7135\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.6773\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.7164\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.7106\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.7250\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.7135\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.7120\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.7091\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.7337\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.6802\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.6643\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7467\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.7164\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1966 - accuracy: 0.7178\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.7308\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.7178\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.7164\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.7308\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.7207\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.7352\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.7221\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.7221\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.6946\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.7207\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.7366\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.7467\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7583\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.7308\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.7265\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7424\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.7467\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.7670\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.7569\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7424\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.7337\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7395\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7482\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.7511\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.7294\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.7424\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.7569\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.7656\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.7352\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.7236\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.7106\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.7366\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.7424\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.7569\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.7670\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.7656\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.7279\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.7540\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.7554\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7627\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.7742\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.7352\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.7279\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7323\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.7482\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.7685\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.7612\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.7670\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.7685\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.7713\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.7757\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.7641\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.7583\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.7786\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.7511\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.7598\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.7685\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.7959\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.7670\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.7627\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.7757\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.7771\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.7815\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.7916\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.7713\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.7670\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.7742\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.7800\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.7959\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.7532\n",
            "Loss: 0.18265096843242645\n",
            "Accuracy: 0.7532467246055603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# load dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "#split the dataset with training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8], test_size=0.1, random_state=30)\n",
        "\n",
        "np.random.seed(155)\n",
        "\n",
        "my_first_nn = Sequential()\n",
        "my_first_nn.add(Dense(64, activation='relu', input_shape=(8,))) #   Hidden Layer\n",
        "my_first_nn.add(Dense(8, activation='relu'))  # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(64, activation='relu'))  #hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "my_first_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "loss, accuracy = my_first_nn.evaluate(X_test, Y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:',accuracy)"
      ],
      "metadata": {
        "id": "frUYVNqwDf9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af106692-d562-4be2-90e9-af462df41510"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.4797 - accuracy: 0.4776\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.6599\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.6483\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.6498\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.6773\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.7004\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.6860\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.6845\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.6773\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.6831\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.6889\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.7048\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.7019\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.6975\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.7164\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.7207\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.7207\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.7192\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7178\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.7279\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.7308\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.7323\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.7352\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.7395\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.7337\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7438\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.7352\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.7424\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.7279\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.7410\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.7236\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7453\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.7453\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.7453\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.7525\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.7424\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.7323\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.7323\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.7525\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.7525\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.7598\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.7496\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.7410\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.7525\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.7424\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.7467\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.7699\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.7554\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.7569\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.7294\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.7496\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.7641\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.7569\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.7482\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.7713\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.7612\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.7757\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.7598\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.7742\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.7786\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.7858\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.7916\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.7685\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.7612\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.7786\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.7800\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.7902\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.7902\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.7771\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.7858\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.7496\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.7656\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.7656\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.7800\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.7858\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.7728\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.7829\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.7858\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.7844\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.7931\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.7945\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.7713\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.7482\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.7800\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.7988\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.7902\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.8003\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.7959\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.7713\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.7902\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.7916\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.7916\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.8032\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.7858\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.7786\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.7916\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.8075\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.8046\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.7988\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.8090\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.7403\n",
            "Loss: 0.17243872582912445\n",
            "Accuracy: 0.7402597665786743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eosjiXPq6uRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))  # Hidden layer\n",
        "model.add(Dense(512, activation='relu'))  #Hidden layer\n",
        "model.add(Dense(30, activation='sigmoid')) #Hidden layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdOyXRg-1vb4",
        "outputId": "80b5c1de-8467-4966-c141-aa2c8bb74a60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.6052 - accuracy: 0.8705 - val_loss: 0.2458 - val_accuracy: 0.9451\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.1753 - accuracy: 0.9576 - val_loss: 0.1381 - val_accuracy: 0.9643\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0993 - accuracy: 0.9734 - val_loss: 0.1061 - val_accuracy: 0.9719\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.0850 - val_accuracy: 0.9753\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.0488 - accuracy: 0.9866 - val_loss: 0.0737 - val_accuracy: 0.9781\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0367 - accuracy: 0.9901 - val_loss: 0.0662 - val_accuracy: 0.9798\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0747 - val_accuracy: 0.9780\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0809 - val_accuracy: 0.9780\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0753 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0630 - val_accuracy: 0.9823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))  # Hidden layer\n",
        "model.add(Dense(512, activation='relu'))  #Hidden layer\n",
        "model.add(Dense(30, activation='sigmoid')) #Hidden layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCRnvGxy2J8h",
        "outputId": "31beb104-ba5b-4ec0-d5c1-1c62f566855c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 1.1260 - accuracy: 0.7240 - val_loss: 0.4883 - val_accuracy: 0.9123\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.3563 - accuracy: 0.9228 - val_loss: 0.2467 - val_accuracy: 0.9404\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.2392 - accuracy: 0.9391 - val_loss: 0.2096 - val_accuracy: 0.9464\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.2051 - accuracy: 0.9461 - val_loss: 0.2210 - val_accuracy: 0.9383\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.1900 - accuracy: 0.9487 - val_loss: 0.1688 - val_accuracy: 0.9546\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.1750 - val_accuracy: 0.9554\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.1759 - accuracy: 0.9533 - val_loss: 0.1764 - val_accuracy: 0.9530\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.1598 - accuracy: 0.9569 - val_loss: 0.1630 - val_accuracy: 0.9577\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1503 - accuracy: 0.9597 - val_loss: 0.1638 - val_accuracy: 0.9557\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.1545 - accuracy: 0.9581 - val_loss: 0.1643 - val_accuracy: 0.9555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# select a random image from the test data\n",
        "test_image_index = np.random.randint(0, len(test_data))\n",
        "test_image = test_data[test_image_index]\n",
        "\n",
        "# reshape the image to its original shape\n",
        "test_image = test_image.reshape((28, 28))\n",
        "\n",
        "# plot the image\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.title('Test image')\n",
        "plt.show()\n",
        "# make a prediction on the test image\n",
        "prediction = model.predict(test_image.reshape((1, dimData)))\n",
        "\n",
        "# get the predicted class label\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# print the predicted class label\n",
        "print('Predicted class:', predicted_class)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# select a random image from the test data\n",
        "test_image_index = np.random.randint(0, len(test_data))\n",
        "test_image = test_data[test_image_index]\n",
        "\n",
        "# reshape the image to its original shape\n",
        "test_image = test_image.reshape((28, 28))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "g3gNYgnH2UAu",
        "outputId": "5d4cd2cc-35e8-4aaa-9fee-2337847c087d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 157ms/step\n",
            "Predicted class: 4\n"
          ]
        }
      ]
    }
  ]
}